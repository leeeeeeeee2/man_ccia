# Data dimensions and the netCDF file format {#dimensions}

_Last update: `r system("git log -1 --format=\"%ad (%h)\" -- 06-data_dimensions.Rmd", intern = TRUE)`_

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
source("R/init_python.R")
source("R/deco_hook.R")
```

```{bash, include=FALSE}
curl -L -o ncdump.py https://gitlab.com/claut/man_ccia/snippets/1734337/raw 
```

## The dimensions of data

In Section \@ref(modelling), we discussed climate models in terms of the dimensions of the model. We can also express the dimensions of our data in analogous terms. When we refer to a dimension, we are referring to some characteristic of our data that will influence the value of a variable of interest. Dimensions may be continuous---for instance a spatial dimension (e.g. latitude or longitude), or a temporal dimension (e.g. time of an observation). In working with climate data, you are likely to find that values are provided across two horizontal spatial dimensions (latitude and longitude) and across a temporal dimension (the time for which the value was projected). Depending on your variable of interest, you may also find that the variable has additional dimensions; for instance, vertical spatial dimensions such as the pressure level. Refer to the CMIP5 [standard output](https://pcmdi.llnl.gov/mips/cmip5/docs/standard_output.pdf) for descriptions of dimensions used CMIP5 models. The most important quality of the dimension is that it should be composed of unique, non-overlapping values. In the following subsections, we will provide a brief overview of dimensionality, and provide visual examples of 0-, 1-, 2-, 3-, and 4-D data. ^[Some of the code used in the graphics in this chapter was modified from the [SWAN wave model](http://www.texample.net/tikz/examples/swan-wave-model/) and [Using signed distance functions to embed contours in discrete grids](http://www.texample.net/tikz/examples/contours-grids/) TikZ examples.] 

```{block, type="rmdcomment"}
Sometimes a dimension in our data does not need to be a continuous or "real world" dimension. Our data is often described by discrete or categorical information and, given that these labels descrbe a characteristic of the data, we can considered them to be an additional dimension. For instance the data for a given point in space and time will be very different between two different models or between two different "experiments" (the scenarios used to drive the models), and definitely different if we are comparing two different variables! 
```


### Zero-dimensional data

An obvious starting point (no pun intended) of our explanation of data dimensions is 0-D data. Zero-dimensional data refers to a single point of information. This point may reflect some measure or value at a specific location, time, and/or set of conditions. We cannot ascertain anything about how this data might change over time or space. Figure \@ref(fig:0d) provides an example of 0-D data. 

```{r 0d, fig.cap="0-D (point) data", fig.align="center"}
knitr::include_graphics("img/0d.png")
```

### One-dimensional data

One dimensional data provides us with an additional piece of information: how does our variable of interest vary over some dimension. We can consider each column of the observed data that we collected in Lab 1 (Sec. \@ref(lab1)) as a good example of 1-D data. We are interested in determining how our variable of interest (`MeanTemp`, for instance) varies over time. Don't be confused by the table format that we used to layout our observed data. The `Date` column in our data set amounts to metadata describing the time (T) dimension. Figure \@ref(fig:1d) provides a visual approximation of one-dimensional data.

```{r 1d, fig.cap="1-D (vector) data", out.width='40%', fig.align="center"}
knitr::include_graphics("img/1d.png")
```

### Two-dimensional data

You are probably most accustomed to working with two-dimensional data sets. In 2-D (rectangular) data, we have a mix of two dimensions of variation. In the case of the data that we collected in Lab 1, we can consider our two dimensions as time (T) and variable. Another common pair of dimensions are latitude and longitude. Recall the "Overlay Map" that you generated on _Conjuntool_ in Lab 2 (Sec. \@ref(lab2)). This is a great example of 2-D data: we include latitude, and longitude, but removed the time dimension by averaging. Refer to Figure \@ref(fig:2d) for a visualization of 2-D data.

```{r 2d, fig.cap="2-D (rectangular) data", out.width='55%', fig.align="center"}
knitr::include_graphics("img/2d.png")
```

### Three-dimensional data

As you have probably ascertained by now, 3-D data refers to a data set that varies over three dimensions. This is most commonly the expression of a set of gridded observations, varying across two spatial axes (X, e.g. longitude and Y, e.g. latitude) and some third dimension such as time (T) or height (Z). The CMIP5 data that you acquired in Lab 2 is an example of three-dimensional data with dimensions (X, Y, and T). When thinking of three-dimensional objects, your mind probably jumps to a cube, which is probably the first 3-D shape any of us learned about in grade school. It is more useful, however, to consider 3-D data as a stack of papers on your desk. Each sheet is a table of X by Y and represents one observation of dimension Z. Have a look at Figure \@ref(fig:3d) to visualize this.  

```{r 3d, fig.cap="3-D (gridded) data", out.width='70%', fig.align="center"}
knitr::include_graphics("img/3d.png")
```

### Data with four or more dimensions

While we won't work with data of four or more dimensions in the exercises in this manual, it is important to note that there is by no means a limit of 3 dimensions to any data set. As we add more dimensions, our data becomes harder for us to visualize. A four-dimensional system, for instance, may include time (T), latitude (Y), longitude (X), and altitude (Z). In Figure \@ref(fig:4d), for instance, we've modelled a four-dimensional data set, where each layer of the Z dimension shown in Figure \@ref(fig:3d) contains several additional layers in an altitude (H) dimension. As we add more dimensions, the shape of our data becomes more and more theoretical, and beyond my capabilities to illustrate! 

```{r 4d, fig.cap="4-D (layered grid) data", out.width='70%', fig.align="center"}
knitr::include_graphics("img/4d.png")
```

## The netCDF file format

Just as higher-dimensioned data becomes difficult for me to illustrate, so too does it become difficult to store in typical text-based file formats like _.csv_ files. Some of the [Global Historical Climatology Network's gridded products](https://www.ncdc.noaa.gov/temp-and-precip/ghcn-gridded-products/), for instance, use an ASCII-formatted grid that looks something like the following: 

```{r, echo=FALSE}
for (month in 1:3) {
  cat(month, "\t1880\n")
  write.table(format(round(matrix(rnorm(20, 100, 40), nrow = 4, ncol = 5)), justify="right"),
            row.names = FALSE, col.names = FALSE, quote = FALSE)
}
```

The above isn't too unwieldy in the example of a 4 by 5 grid with three layers. The actual data set, however, is on a 36 by 72 grid with over 100 years of data. That required me to do a little bit of [cheeky parsing](https://gitlab.com/ConorIA/claut/blob/master/R/parse_ASCII_grid.R) to read the data into R for a previous analysis. Another disadvantage of text-based data is that it usually requires a separate README file with metadata such as the latitude and longitude coordinates for each cell, and basic facts about the data such as the units, method of collection, licensing and use, etc. 

Finding solutions to these challenges falls within the mandate of the [Unidata program](https://www.unidata.ucar.edu/), managed by the [University Corporation for Atmospheric Research](https://www.ucar.edu/). Unidata developed the Network Common Data Form (netCDF) file format as a means of providing an open, portable standard for the storage of geoscience data for education and research. There are some key features of the netCDF file format that make it a good choice for climate scientists.^[See Unidata's [netCDF factsheet](https://www.unidata.ucar.edu/publications/factsheets/current/factsheet_netcdf.pdf).] 

- The format is self-describing: all of the metadata about the file and its contents are contained within the netCDF file, without the need for an external metadata server or file. 
- NetCDF files are portable across different types of computers. 
- The netCDF file also allows for versatility in analysis due to its efficient storage nature, the specifics of which are beyond the scope of this preface.   
- Perhaps most importantly, support for netCDF files is active and ongoing, and software has been written to access these files in Python, R, and many other programming languages on Linux, Mac, Windows, and more.

The above benefits of netCDF files have led to the format being endorsed by a number of significant government and academic agencies dedicated to the management of geoscience data. For more details on the netCDF file format, you can visit the [netCDF documentation](https://www.unidata.ucar.edu/software/netcdf/docs/index.html).

The `ncdump` program is a command-line utility (run in `bash`) that is a useful tool to begin to understand the contents of your netCDF files. The command will output information on the dimensions of your data set, the size of each dimension, and additional metadata like units and variable names. The following, for instance, is the output of that command when run on some [miniature netCDF files](https://claut.gitlab.io/man_ccia/data/mini/index.html) that we have created for this book. You will surely see much more output if you run the tool on the files that you downloaded in Lab 2!

```{bash, echo=TRUE, deco=list(label="Shell", bc="#000000", tc="#ffffff", icon=list(style="fas", name="terminal"))}
ncdump -h data/mini/tas_Amon_CanESM2_historical_r1i1p1_198001-200512_mini.nc
```

You can check to see if `ncdump` is available on your computer by running `which ncdump`. If it is not installed, fear not! We have written an analogous utility for Python, which you can find [here](https://gitlab.com/claut/man_ccia/snippets/1734337/raw). Download it to your computer import the file, and run it like this:

```{r, include=FALSE}
source_python('ncdump.py')
```
```{python, echo=TRUE, deco=list()}
ncdump("data/mini/tas_Amon_CanESM2_historical_r1i1p1_198001-200512_mini.nc")
```

In Lab 3 (Sec. \@ref(lab3)), you will learn how to read data from a netCDF file in Python. In that lab, we will focus on a single grid box, but keep in mind that the netCDF files that you acquired in Lab 2 contain much more data, and you can re-use the same files for future analyses of other areas, entire regions or even the entire globe! 

```{block, type='rmdcomment'}
We presented netCDF here, as it is the file format that we will be using and is the standard format for the the CMIP projects (See: [CMIP5](https://pcmdi.llnl.gov/mips/cmip5/requirements.html);  [CMIP6](https://pcmdi.llnl.gov/CMIP6/Guide/modelers.html#5-model-output-requirements). You are likely, however, to come across data in other gridded data formats. The [GRIB](https://weather.gc.ca/grib/what_is_GRIB_e.html) format, for instance, is common in meteorology and weather forecasting and is used by the Meteorological Service of Canada to provide output from many of the Canadian Meteorological Centre's Numerical Weather Prediction models and is used for many of the data sets provided by the Copernicus Climate Change Service [Climate Date Store](https://cds.climate.copernicus.eu/cdsapp#!/search?type=dataset). The Hierarchical Data Format ([HDF5](https://www.hdfgroup.org/solutions/hdf5/)) is another high-performance $n$-dimensional data format, and is (partially) [interoperatble](https://www.unidata.ucar.edu/software/netcdf/docs/interoperability_hdf5.html) with netCDF-4. HDF5 is one of the [standards](https://earthdata.nasa.gov/esdis/eso/standards-and-references/hdf5) used for NASA Earth Data data sets. There are also emerging formats, such as [zarr](https://zarr.readthedocs.io/en/stable/), that seek to improve on existing formats, and may eventually become the format of choice for scientists and scientific organizations.
```

```{bash cleanup, include=FALSE}
rm ncdump.py
```